{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a1b97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and Imports\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "\n",
    "# Project imports\n",
    "from src.datamodules import APTOSDataModule\n",
    "from src.models import DRModel\n",
    "from src.utils import quadratic_weighted_kappa, compute_confusion_matrix\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch Lightning version: {pl.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff81e0b",
   "metadata": {},
   "source": [
    "## 2. Configuration Management\n",
    "\n",
    "We use Hydra for configuration management. Let's load and inspect the configs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a89441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration manually (for notebook use)\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Load individual configs\n",
    "config_path = Path('../conf')\n",
    "\n",
    "main_cfg = OmegaConf.load(config_path / 'config.yaml')\n",
    "dataset_cfg = OmegaConf.load(config_path / 'dataset' / 'aptos.yaml')\n",
    "model_cfg = OmegaConf.load(config_path / 'model' / 'efficientnet_b5.yaml')\n",
    "training_cfg = OmegaConf.load(config_path / 'training' / 'default.yaml')\n",
    "loss_cfg = OmegaConf.load(config_path / 'loss' / 'regression.yaml')\n",
    "\n",
    "# Merge configs\n",
    "cfg = OmegaConf.merge(\n",
    "    main_cfg,\n",
    "    {'dataset': dataset_cfg},\n",
    "    {'model': model_cfg},\n",
    "    {'training': training_cfg},\n",
    "    {'loss': loss_cfg}\n",
    ")\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf97569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration overrides for notebook\n",
    "# Adjust these based on your hardware\n",
    "\n",
    "OVERRIDES = {\n",
    "    'data_dir': '../data/aptos',\n",
    "    'training': {\n",
    "        'batch_size': 16,  # Reduce if OOM\n",
    "        'num_workers': 4,\n",
    "        'epochs': 30,\n",
    "        'accumulate_grad_batches': 2,\n",
    "    },\n",
    "    'model': {\n",
    "        'pretrained': True,\n",
    "        'head_type': 'regression',\n",
    "    }\n",
    "}\n",
    "\n",
    "cfg = OmegaConf.merge(cfg, OmegaConf.create(OVERRIDES))\n",
    "print(\"Updated batch_size:\", cfg.training.batch_size)\n",
    "print(\"Updated epochs:\", cfg.training.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a607fa",
   "metadata": {},
   "source": [
    "## 3. Data Loading & Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57af563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataModule\n",
    "data_dir = Path(cfg.data_dir)\n",
    "\n",
    "datamodule = APTOSDataModule(\n",
    "    data_dir=data_dir,\n",
    "    batch_size=cfg.training.batch_size,\n",
    "    num_workers=cfg.training.num_workers,\n",
    "    image_size=cfg.model.input_size,\n",
    "    use_processed=True,\n",
    "    val_split=0.2,\n",
    "    seed=cfg.training.seed\n",
    ")\n",
    "\n",
    "# Setup data\n",
    "datamodule.setup()\n",
    "\n",
    "print(f\"Training samples: {len(datamodule.train_dataset)}\")\n",
    "print(f\"Validation samples: {len(datamodule.val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023cdda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a training batch\n",
    "train_loader = datamodule.train_dataloader()\n",
    "batch = next(iter(train_loader))\n",
    "images, labels = batch\n",
    "\n",
    "print(f\"Batch shape: {images.shape}\")\n",
    "print(f\"Labels: {labels.numpy()}\")\n",
    "\n",
    "# Denormalize for visualization\n",
    "mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)\n",
    "std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)\n",
    "images_denorm = images * std + mean\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "class_names = ['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferative']\n",
    "\n",
    "for idx, ax in enumerate(axes.flat):\n",
    "    if idx < len(images):\n",
    "        img = images_denorm[idx].permute(1, 2, 0).numpy().clip(0, 1)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"{class_names[labels[idx]]} (Grade {labels[idx]})\")\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.suptitle('Training Batch Sample (with augmentation)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd29614f",
   "metadata": {},
   "source": [
    "## 4. Model Architecture Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a8120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = DRModel(\n",
    "    backbone=cfg.model.backbone,\n",
    "    num_classes=cfg.dataset.num_classes,\n",
    "    head_type=cfg.model.head_type,\n",
    "    pretrained=cfg.model.pretrained,\n",
    "    dropout=cfg.model.dropout,\n",
    "    pooling=cfg.model.pooling\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3204f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary\n",
    "from torchinfo import summary\n",
    "\n",
    "input_size = (1, 3, cfg.model.input_size, cfg.model.input_size)\n",
    "summary(model, input_size=input_size, col_names=['input_size', 'output_size', 'num_params', 'trainable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a453576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Non-trainable parameters: {total_params - trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef4cad5",
   "metadata": {},
   "source": [
    "## 5. Lightning Module & Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8fade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lightning Module Definition\n",
    "class DRLightningModule(pl.LightningModule):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        # Model\n",
    "        self.model = DRModel(\n",
    "            backbone=cfg.model.backbone,\n",
    "            num_classes=cfg.dataset.num_classes,\n",
    "            head_type=cfg.model.head_type,\n",
    "            pretrained=cfg.model.pretrained,\n",
    "            dropout=cfg.model.dropout,\n",
    "            pooling=cfg.model.pooling\n",
    "        )\n",
    "        \n",
    "        # Loss\n",
    "        if cfg.model.head_type == 'regression':\n",
    "            self.criterion = nn.MSELoss()\n",
    "        else:\n",
    "            weights = torch.tensor(cfg.dataset.class_weights)\n",
    "            self.criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "        \n",
    "        # Metrics storage\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        \n",
    "        if self.cfg.model.head_type == 'regression':\n",
    "            outputs = outputs.squeeze()\n",
    "            loss = self.criterion(outputs, labels.float())\n",
    "            preds = outputs.round().clamp(0, 4).long()\n",
    "        else:\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "        \n",
    "        self.training_step_outputs.append({\n",
    "            'loss': loss.detach(),\n",
    "            'preds': preds.detach(),\n",
    "            'labels': labels.detach()\n",
    "        })\n",
    "        \n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def on_training_epoch_end(self):\n",
    "        all_preds = torch.cat([x['preds'] for x in self.training_step_outputs])\n",
    "        all_labels = torch.cat([x['labels'] for x in self.training_step_outputs])\n",
    "        \n",
    "        qwk = quadratic_weighted_kappa(all_preds.cpu().numpy(), all_labels.cpu().numpy())\n",
    "        self.log('train_qwk', qwk, prog_bar=True)\n",
    "        \n",
    "        self.training_step_outputs.clear()\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        outputs = self(images)\n",
    "        \n",
    "        if self.cfg.model.head_type == 'regression':\n",
    "            outputs = outputs.squeeze()\n",
    "            loss = self.criterion(outputs, labels.float())\n",
    "            preds = outputs.round().clamp(0, 4).long()\n",
    "        else:\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "        \n",
    "        self.validation_step_outputs.append({\n",
    "            'loss': loss.detach(),\n",
    "            'preds': preds.detach(),\n",
    "            'labels': labels.detach(),\n",
    "            'outputs': outputs.detach()\n",
    "        })\n",
    "        \n",
    "        self.log('val_loss', loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        all_preds = torch.cat([x['preds'] for x in self.validation_step_outputs])\n",
    "        all_labels = torch.cat([x['labels'] for x in self.validation_step_outputs])\n",
    "        all_outputs = torch.cat([x['outputs'] for x in self.validation_step_outputs])\n",
    "        \n",
    "        qwk = quadratic_weighted_kappa(all_preds.cpu().numpy(), all_labels.cpu().numpy())\n",
    "        accuracy = (all_preds == all_labels).float().mean().item()\n",
    "        \n",
    "        self.log('val_qwk', qwk, prog_bar=True)\n",
    "        self.log('val_accuracy', accuracy, prog_bar=True)\n",
    "        \n",
    "        self.validation_step_outputs.clear()\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.cfg.training.lr,\n",
    "            weight_decay=self.cfg.training.weight_decay\n",
    "        )\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=self.cfg.training.epochs,\n",
    "            eta_min=self.cfg.training.lr * 0.01\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'interval': 'epoch'\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1bc851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lightning Module\n",
    "lightning_model = DRLightningModule(cfg)\n",
    "print(\"Lightning module created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        dirpath='../checkpoints',\n",
    "        filename='dr-{epoch:02d}-{val_qwk:.4f}',\n",
    "        monitor='val_qwk',\n",
    "        mode='max',\n",
    "        save_top_k=3,\n",
    "        save_last=True,\n",
    "        verbose=True\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_qwk',\n",
    "        mode='max',\n",
    "        patience=5,\n",
    "        verbose=True\n",
    "    ),\n",
    "    LearningRateMonitor(logging_interval='epoch')\n",
    "]\n",
    "\n",
    "# Logger\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir='../logs',\n",
    "    name='dr_training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a946797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=cfg.training.epochs,\n",
    "    accelerator='auto',\n",
    "    devices=1,\n",
    "    precision='16-mixed',  # Mixed precision for faster training\n",
    "    callbacks=callbacks,\n",
    "    logger=logger,\n",
    "    accumulate_grad_batches=cfg.training.accumulate_grad_batches,\n",
    "    gradient_clip_val=cfg.training.gradient_clip_val,\n",
    "    log_every_n_steps=10,\n",
    "    deterministic=False,\n",
    "    enable_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"Trainer configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d23080",
   "metadata": {},
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a56fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training!\n",
    "# Uncomment the line below to train\n",
    "\n",
    "# trainer.fit(lightning_model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c7f5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View training logs with TensorBoard\n",
    "# Run this in a terminal:\n",
    "# tensorboard --logdir=logs/dr_training\n",
    "\n",
    "# Or use the magic command in Jupyter:\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir ../logs/dr_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a8905c",
   "metadata": {},
   "source": [
    "## 7. Threshold Optimization\n",
    "\n",
    "For regression output, we need to find optimal thresholds to convert continuous predictions to classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbdd60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import ThresholdOptimizer\n",
    "\n",
    "# Load best checkpoint\n",
    "checkpoint_path = '../checkpoints/last.ckpt'  # or best checkpoint\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    trained_model = DRLightningModule.load_from_checkpoint(checkpoint_path, cfg=cfg)\n",
    "    trained_model.eval()\n",
    "    trained_model.freeze()\n",
    "    print(\"Model loaded from checkpoint!\")\n",
    "else:\n",
    "    print(\"No checkpoint found. Using untrained model for demonstration.\")\n",
    "    trained_model = lightning_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4036fb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect validation predictions\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "trained_model = trained_model.to(device)\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "val_loader = datamodule.val_dataloader()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = trained_model(images).squeeze().cpu().numpy()\n",
    "        all_preds.extend(outputs)\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "print(f\"Collected {len(all_preds)} predictions\")\n",
    "print(f\"Prediction range: [{all_preds.min():.3f}, {all_preds.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize thresholds\n",
    "optimizer = ThresholdOptimizer(num_classes=5)\n",
    "optimal_thresholds = optimizer.optimize(all_preds, all_labels)\n",
    "\n",
    "print(f\"Optimal thresholds: {optimal_thresholds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a7b79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare default vs optimized thresholds\n",
    "default_thresholds = [0.5, 1.5, 2.5, 3.5]\n",
    "\n",
    "# Apply thresholds\n",
    "def apply_thresholds(preds, thresholds):\n",
    "    classes = np.zeros_like(preds, dtype=int)\n",
    "    for i, thresh in enumerate(thresholds):\n",
    "        classes[preds > thresh] = i + 1\n",
    "    return classes\n",
    "\n",
    "preds_default = apply_thresholds(all_preds, default_thresholds)\n",
    "preds_optimized = apply_thresholds(all_preds, optimal_thresholds)\n",
    "\n",
    "qwk_default = quadratic_weighted_kappa(preds_default, all_labels)\n",
    "qwk_optimized = quadratic_weighted_kappa(preds_optimized, all_labels)\n",
    "\n",
    "print(f\"QWK with default thresholds: {qwk_default:.4f}\")\n",
    "print(f\"QWK with optimized thresholds: {qwk_optimized:.4f}\")\n",
    "print(f\"Improvement: {(qwk_optimized - qwk_default) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5ebf7e",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f362df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm = confusion_matrix(all_labels, preds_optimized)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues',\n",
    "    xticklabels=['No DR', 'Mild', 'Moderate', 'Severe', 'PDR'],\n",
    "    yticklabels=['No DR', 'Mild', 'Moderate', 'Severe', 'PDR']\n",
    ")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title(f'Confusion Matrix (QWK: {qwk_optimized:.4f})')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74568aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "class_names = ['No DR', 'Mild', 'Moderate', 'Severe', 'PDR']\n",
    "print(classification_report(all_labels, preds_optimized, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cd867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class metrics visualization\n",
    "report = classification_report(all_labels, preds_optimized, target_names=class_names, output_dict=True)\n",
    "\n",
    "metrics_df = pd.DataFrame(report).T.iloc[:-3]  # Exclude avg rows\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "metrics = ['precision', 'recall', 'f1-score']\n",
    "colors = ['steelblue', 'darkorange', 'forestgreen']\n",
    "\n",
    "for ax, metric, color in zip(axes, metrics, colors):\n",
    "    metrics_df[metric].plot(kind='bar', ax=ax, color=color, edgecolor='black')\n",
    "    ax.set_title(f'{metric.capitalize()} by Class')\n",
    "    ax.set_ylabel(metric.capitalize())\n",
    "    ax.set_xlabel('DR Severity')\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, v in enumerate(metrics_df[metric]):\n",
    "        ax.text(i, v + 0.02, f'{v:.2f}', ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d86ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save optimized thresholds\n",
    "import json\n",
    "\n",
    "thresholds_path = '../checkpoints/thresholds.json'\n",
    "with open(thresholds_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'thresholds': optimal_thresholds.tolist() if hasattr(optimal_thresholds, 'tolist') else list(optimal_thresholds),\n",
    "        'qwk': float(qwk_optimized),\n",
    "        'num_samples': len(all_labels)\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"Thresholds saved to {thresholds_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a2dc64",
   "metadata": {},
   "source": [
    "## 9. Export Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b44a78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to ONNX\n",
    "trained_model.eval()\n",
    "trained_model = trained_model.cpu()\n",
    "\n",
    "dummy_input = torch.randn(1, 3, cfg.model.input_size, cfg.model.input_size)\n",
    "onnx_path = '../checkpoints/dr_model.onnx'\n",
    "\n",
    "torch.onnx.export(\n",
    "    trained_model.model,\n",
    "    dummy_input,\n",
    "    onnx_path,\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Model exported to {onnx_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b7e174",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we:\n",
    "1. ✅ Loaded and configured the training pipeline\n",
    "2. ✅ Verified data loading and augmentation\n",
    "3. ✅ Built the model architecture (EfficientNet-B5 + Regression head)\n",
    "4. ✅ Set up PyTorch Lightning training with callbacks\n",
    "5. ✅ Optimized regression-to-class thresholds\n",
    "6. ✅ Evaluated model performance (QWK, confusion matrix)\n",
    "7. ✅ Exported model for deployment\n",
    "\n",
    "### Next Steps\n",
    "- Run the training with `trainer.fit()`\n",
    "- Fine-tune hyperparameters based on validation QWK\n",
    "- Try cross-validation for more robust evaluation\n",
    "- Explore Grad-CAM for model interpretability"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
