{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558111c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "# Project imports\n",
    "from src.models import DRModel\n",
    "from src.utils import BenGrahamPreprocessor\n",
    "from src.xai import GradCAM, IntegratedGradients\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f99395",
   "metadata": {},
   "source": [
    "## 1. Load Model & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be34aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'model': {\n",
    "        'backbone': 'efficientnet_b5',\n",
    "        'num_classes': 5,\n",
    "        'head_type': 'regression',\n",
    "        'pretrained': False,  # We'll load weights\n",
    "        'dropout': 0.5,\n",
    "        'pooling': 'gem'\n",
    "    },\n",
    "    'input_size': 456,\n",
    "    'checkpoint_path': '../checkpoints/last.ckpt',\n",
    "    'thresholds_path': '../checkpoints/thresholds.json'\n",
    "}\n",
    "\n",
    "# Class names for ICDR scale\n",
    "CLASS_NAMES = {\n",
    "    0: 'No DR',\n",
    "    1: 'Mild NPDR',\n",
    "    2: 'Moderate NPDR', \n",
    "    3: 'Severe NPDR',\n",
    "    4: 'Proliferative DR'\n",
    "}\n",
    "\n",
    "# Clinical descriptions\n",
    "CLINICAL_DESCRIPTIONS = {\n",
    "    0: 'No visible signs of diabetic retinopathy. Continue annual screening.',\n",
    "    1: 'Mild nonproliferative DR. Microaneurysms only. Annual follow-up recommended.',\n",
    "    2: 'Moderate nonproliferative DR. More than microaneurysms. Follow-up in 6 months.',\n",
    "    3: 'Severe nonproliferative DR. Significant hemorrhages. Refer to ophthalmologist.',\n",
    "    4: 'Proliferative DR. Neovascularization present. Urgent referral required.'\n",
    "}\n",
    "\n",
    "SEVERITY_COLORS = {\n",
    "    0: '#2ECC71',  # Green\n",
    "    1: '#F1C40F',  # Yellow\n",
    "    2: '#E67E22',  # Orange\n",
    "    3: '#E74C3C',  # Red\n",
    "    4: '#9B59B6'   # Purple\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af786308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create model\n",
    "model = DRModel(\n",
    "    backbone=CONFIG['model']['backbone'],\n",
    "    num_classes=CONFIG['model']['num_classes'],\n",
    "    head_type=CONFIG['model']['head_type'],\n",
    "    pretrained=CONFIG['model']['pretrained'],\n",
    "    dropout=CONFIG['model']['dropout'],\n",
    "    pooling=CONFIG['model']['pooling']\n",
    ")\n",
    "\n",
    "# Load weights if available\n",
    "if os.path.exists(CONFIG['checkpoint_path']):\n",
    "    checkpoint = torch.load(CONFIG['checkpoint_path'], map_location=device)\n",
    "    state_dict = checkpoint.get('state_dict', checkpoint)\n",
    "    # Remove 'model.' prefix if present\n",
    "    state_dict = {k.replace('model.', ''): v for k, v in state_dict.items()}\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    print(\"✓ Loaded trained weights\")\n",
    "else:\n",
    "    print(\"⚠ No checkpoint found, using random weights for demo\")\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load thresholds\n",
    "if os.path.exists(CONFIG['thresholds_path']):\n",
    "    with open(CONFIG['thresholds_path'], 'r') as f:\n",
    "        thresholds_data = json.load(f)\n",
    "        THRESHOLDS = thresholds_data['thresholds']\n",
    "    print(f\"✓ Loaded optimized thresholds: {THRESHOLDS}\")\n",
    "else:\n",
    "    THRESHOLDS = [0.5, 1.5, 2.5, 3.5]\n",
    "    print(f\"Using default thresholds: {THRESHOLDS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a285b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline\n",
    "preprocessor = BenGrahamPreprocessor(output_size=CONFIG['input_size'])\n",
    "\n",
    "# Transform for model input\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dc5b20",
   "metadata": {},
   "source": [
    "## 2. Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20de181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, preprocessor, transform, size):\n",
    "    \"\"\"Load and preprocess an image.\"\"\"\n",
    "    # Load image\n",
    "    image = cv2.imread(str(image_path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Apply Ben Graham preprocessing\n",
    "    processed = preprocessor.process(image)\n",
    "    \n",
    "    # Resize to model input size\n",
    "    processed = cv2.resize(processed, (size, size))\n",
    "    \n",
    "    # Apply transforms\n",
    "    tensor = transform(processed)\n",
    "    \n",
    "    return processed, tensor\n",
    "\n",
    "\n",
    "def apply_thresholds(prediction, thresholds):\n",
    "    \"\"\"Convert regression output to class.\"\"\"\n",
    "    pred_class = 0\n",
    "    for i, thresh in enumerate(thresholds):\n",
    "        if prediction > thresh:\n",
    "            pred_class = i + 1\n",
    "    return pred_class\n",
    "\n",
    "\n",
    "def predict_single(image_path, model, preprocessor, transform, thresholds, device):\n",
    "    \"\"\"Predict DR grade for a single image.\"\"\"\n",
    "    # Preprocess\n",
    "    processed_image, tensor = preprocess_image(\n",
    "        image_path, preprocessor, transform, CONFIG['input_size']\n",
    "    )\n",
    "    \n",
    "    # Add batch dimension\n",
    "    tensor = tensor.unsqueeze(0).to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        output = model(tensor).squeeze().cpu().item()\n",
    "    \n",
    "    # Apply thresholds\n",
    "    pred_class = apply_thresholds(output, thresholds)\n",
    "    \n",
    "    return {\n",
    "        'raw_score': output,\n",
    "        'class': pred_class,\n",
    "        'class_name': CLASS_NAMES[pred_class],\n",
    "        'description': CLINICAL_DESCRIPTIONS[pred_class],\n",
    "        'processed_image': processed_image\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5d0512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_tta(image_path, model, preprocessor, transform, thresholds, device, n_tta=8):\n",
    "    \"\"\"Predict with Test Time Augmentation.\"\"\"\n",
    "    # Preprocess\n",
    "    processed_image, base_tensor = preprocess_image(\n",
    "        image_path, preprocessor, transform, CONFIG['input_size']\n",
    "    )\n",
    "    \n",
    "    # TTA augmentations\n",
    "    tta_tensors = [base_tensor]  # Original\n",
    "    \n",
    "    # Horizontal flip\n",
    "    tta_tensors.append(torch.flip(base_tensor, dims=[2]))\n",
    "    \n",
    "    # Vertical flip\n",
    "    tta_tensors.append(torch.flip(base_tensor, dims=[1]))\n",
    "    \n",
    "    # Both flips\n",
    "    tta_tensors.append(torch.flip(base_tensor, dims=[1, 2]))\n",
    "    \n",
    "    # Rotations (90, 180, 270)\n",
    "    for k in [1, 2, 3]:\n",
    "        rotated = torch.rot90(base_tensor, k, dims=[1, 2])\n",
    "        tta_tensors.append(rotated)\n",
    "    \n",
    "    # Limit to n_tta\n",
    "    tta_tensors = tta_tensors[:n_tta]\n",
    "    \n",
    "    # Stack and predict\n",
    "    batch = torch.stack(tta_tensors).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(batch).squeeze().cpu().numpy()\n",
    "    \n",
    "    # Average predictions\n",
    "    avg_output = outputs.mean()\n",
    "    std_output = outputs.std()\n",
    "    \n",
    "    # Apply thresholds\n",
    "    pred_class = apply_thresholds(avg_output, thresholds)\n",
    "    \n",
    "    return {\n",
    "        'raw_score': avg_output,\n",
    "        'std': std_output,\n",
    "        'individual_scores': outputs,\n",
    "        'class': pred_class,\n",
    "        'class_name': CLASS_NAMES[pred_class],\n",
    "        'description': CLINICAL_DESCRIPTIONS[pred_class],\n",
    "        'processed_image': processed_image,\n",
    "        'confidence': 1 - (std_output / 2)  # Rough confidence estimate\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b67a0b5",
   "metadata": {},
   "source": [
    "## 3. Single Image Inference Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8bbcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo with a sample image\n",
    "# Replace with your own image path\n",
    "sample_image_path = Path('../data/aptos/processed/sample_image.png')\n",
    "\n",
    "# For demo, create a random image if no real data\n",
    "if not sample_image_path.exists():\n",
    "    print(\"No sample image found. Creating synthetic demo...\")\n",
    "    # Create synthetic fundus-like image for demo\n",
    "    demo_image = np.zeros((512, 512, 3), dtype=np.uint8)\n",
    "    cv2.circle(demo_image, (256, 256), 200, (100, 50, 50), -1)\n",
    "    cv2.circle(demo_image, (256, 256), 180, (150, 80, 60), -1)\n",
    "    # Add some features\n",
    "    cv2.circle(demo_image, (200, 200), 20, (200, 100, 100), -1)  # Optic disc\n",
    "    cv2.line(demo_image, (150, 256), (350, 256), (120, 60, 60), 3)  # Vessels\n",
    "    demo_image_path = Path('../data/demo_image.png')\n",
    "    demo_image_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    cv2.imwrite(str(demo_image_path), cv2.cvtColor(demo_image, cv2.COLOR_RGB2BGR))\n",
    "    sample_image_path = demo_image_path\n",
    "    print(f\"Created demo image at {sample_image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0befa299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "if sample_image_path.exists():\n",
    "    result = predict_with_tta(\n",
    "        sample_image_path, model, preprocessor, transform, THRESHOLDS, device\n",
    "    )\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"PREDICTION RESULT\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Raw Score: {result['raw_score']:.3f} (std: {result['std']:.3f})\")\n",
    "    print(f\"Predicted Class: {result['class']} - {result['class_name']}\")\n",
    "    print(f\"Confidence: {result['confidence']:.1%}\")\n",
    "    print(f\"\\nClinical Note: {result['description']}\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a74e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize result\n",
    "if sample_image_path.exists():\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Original\n",
    "    original = cv2.imread(str(sample_image_path))\n",
    "    original = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
    "    axes[0].imshow(original)\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Preprocessed\n",
    "    axes[1].imshow(result['processed_image'])\n",
    "    axes[1].set_title('Ben Graham Preprocessed')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Prediction visualization\n",
    "    grades = list(range(5))\n",
    "    colors = [SEVERITY_COLORS[g] for g in grades]\n",
    "    bars = axes[2].bar(grades, [1 if g == result['class'] else 0.1 for g in grades], color=colors)\n",
    "    \n",
    "    # Highlight predicted class\n",
    "    bars[result['class']].set_edgecolor('black')\n",
    "    bars[result['class']].set_linewidth(3)\n",
    "    \n",
    "    axes[2].axhline(y=result['raw_score'] / 4, color='red', linestyle='--', linewidth=2, label=f'Score: {result[\"raw_score\"]:.2f}')\n",
    "    axes[2].set_xticks(grades)\n",
    "    axes[2].set_xticklabels(['No DR', 'Mild', 'Mod', 'Severe', 'PDR'])\n",
    "    axes[2].set_ylabel('Prediction')\n",
    "    axes[2].set_title(f'Prediction: {result[\"class_name\"]}')\n",
    "    axes[2].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbee765d",
   "metadata": {},
   "source": [
    "## 4. Grad-CAM Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa4b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Grad-CAM\n",
    "# For EfficientNet, we use the last convolutional layer\n",
    "target_layer = model.backbone.features[-1]  # Last feature layer\n",
    "gradcam = GradCAM(model, target_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dedc219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_gradcam(image_path, model, gradcam, preprocessor, transform, device):\n",
    "    \"\"\"Generate and visualize Grad-CAM heatmap.\"\"\"\n",
    "    # Preprocess\n",
    "    processed, tensor = preprocess_image(\n",
    "        image_path, preprocessor, transform, CONFIG['input_size']\n",
    "    )\n",
    "    tensor = tensor.unsqueeze(0).to(device)\n",
    "    \n",
    "    # Generate Grad-CAM\n",
    "    heatmap, pred = gradcam(tensor)\n",
    "    heatmap = heatmap.cpu().numpy()\n",
    "    \n",
    "    # Resize heatmap to image size\n",
    "    heatmap = cv2.resize(heatmap, (processed.shape[1], processed.shape[0]))\n",
    "    \n",
    "    # Create colored heatmap\n",
    "    heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
    "    heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Superimpose on original\n",
    "    superimposed = cv2.addWeighted(processed, 0.6, heatmap_colored, 0.4, 0)\n",
    "    \n",
    "    return processed, heatmap, superimposed, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4344575",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_image_path.exists():\n",
    "    processed, heatmap, superimposed, pred = visualize_gradcam(\n",
    "        sample_image_path, model, gradcam, preprocessor, transform, device\n",
    "    )\n",
    "    \n",
    "    pred_class = apply_thresholds(pred.item(), THRESHOLDS)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    \n",
    "    axes[0].imshow(processed)\n",
    "    axes[0].set_title('Preprocessed Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    im = axes[1].imshow(heatmap, cmap='jet')\n",
    "    axes[1].set_title('Grad-CAM Heatmap')\n",
    "    axes[1].axis('off')\n",
    "    plt.colorbar(im, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    axes[2].imshow(superimposed)\n",
    "    axes[2].set_title('Overlay')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    # Threshold the heatmap to show high attention regions\n",
    "    mask = heatmap > 0.5\n",
    "    highlighted = processed.copy()\n",
    "    highlighted[~mask] = highlighted[~mask] * 0.3  # Dim low attention areas\n",
    "    axes[3].imshow(highlighted)\n",
    "    axes[3].set_title('High Attention Regions')\n",
    "    axes[3].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Grad-CAM Analysis - Prediction: {CLASS_NAMES[pred_class]} (Score: {pred.item():.3f})', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26842804",
   "metadata": {},
   "source": [
    "## 5. Batch Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e79cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_predict(image_paths, model, preprocessor, transform, thresholds, device, batch_size=16):\n",
    "    \"\"\"Run batch inference on multiple images.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for i in range(0, len(image_paths), batch_size):\n",
    "        batch_paths = image_paths[i:i+batch_size]\n",
    "        batch_tensors = []\n",
    "        \n",
    "        for path in batch_paths:\n",
    "            _, tensor = preprocess_image(path, preprocessor, transform, CONFIG['input_size'])\n",
    "            batch_tensors.append(tensor)\n",
    "        \n",
    "        batch = torch.stack(batch_tensors).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch).squeeze().cpu().numpy()\n",
    "        \n",
    "        if outputs.ndim == 0:\n",
    "            outputs = [outputs.item()]\n",
    "        \n",
    "        for path, output in zip(batch_paths, outputs):\n",
    "            pred_class = apply_thresholds(output, thresholds)\n",
    "            results.append({\n",
    "                'image': path.name,\n",
    "                'raw_score': output,\n",
    "                'predicted_class': pred_class,\n",
    "                'class_name': CLASS_NAMES[pred_class]\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8cdc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: batch inference on test set\n",
    "test_images_dir = Path('../data/aptos/test_images')\n",
    "\n",
    "if test_images_dir.exists():\n",
    "    image_paths = list(test_images_dir.glob('*.png'))[:50]  # First 50 images\n",
    "    \n",
    "    if image_paths:\n",
    "        print(f\"Running inference on {len(image_paths)} images...\")\n",
    "        results_df = batch_predict(\n",
    "            image_paths, model, preprocessor, transform, THRESHOLDS, device\n",
    "        )\n",
    "        \n",
    "        print(\"\\nResults:\")\n",
    "        print(results_df.head(10))\n",
    "        \n",
    "        # Distribution\n",
    "        print(\"\\nPrediction Distribution:\")\n",
    "        print(results_df['class_name'].value_counts())\n",
    "else:\n",
    "    print(\"Test images directory not found. Skipping batch inference demo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bba84c",
   "metadata": {},
   "source": [
    "## 6. Clinical Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02253ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clinical_report(image_path, result, save_path=None):\n",
    "    \"\"\"Generate a clinical report for DR screening.\"\"\"\n",
    "    report = f\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║           DIABETIC RETINOPATHY SCREENING REPORT                  ║\n",
    "╠══════════════════════════════════════════════════════════════════╣\n",
    "║ Image: {str(image_path.name)[:50]:<50} ║\n",
    "╠══════════════════════════════════════════════════════════════════╣\n",
    "║                                                                  ║\n",
    "║  DIAGNOSIS: {result['class_name']:<45} ║\n",
    "║  Grade: {result['class']}/4                                              ║\n",
    "║  Confidence: {result.get('confidence', 0.0):.1%}                                          ║\n",
    "║                                                                  ║\n",
    "╠══════════════════════════════════════════════════════════════════╣\n",
    "║  CLINICAL NOTES:                                                 ║\n",
    "║  {result['description'][:60]:<60} ║\n",
    "║  {result['description'][60:120] if len(result['description']) > 60 else '':<60} ║\n",
    "║                                                                  ║\n",
    "╠══════════════════════════════════════════════════════════════════╣\n",
    "║  RECOMMENDATIONS:                                                ║\n",
    "\"\"\"\n",
    "    \n",
    "    recommendations = {\n",
    "        0: ['Continue annual diabetic eye examinations',\n",
    "            'Maintain blood sugar control',\n",
    "            'Regular blood pressure monitoring'],\n",
    "        1: ['Follow-up examination in 12 months',\n",
    "            'Optimize glycemic control',\n",
    "            'Consider referral if progression'],\n",
    "        2: ['Follow-up examination in 6 months',\n",
    "            'Ophthalmology consultation recommended',\n",
    "            'Intensive glycemic management'],\n",
    "        3: ['Urgent ophthalmology referral',\n",
    "            'Consider panretinal photocoagulation',\n",
    "            'Close blood sugar monitoring'],\n",
    "        4: ['IMMEDIATE ophthalmology referral',\n",
    "            'Treatment required within 2 weeks',\n",
    "            'High risk of vision loss']\n",
    "    }\n",
    "    \n",
    "    for rec in recommendations[result['class']]:\n",
    "        report += f\"║  • {rec:<59} ║\\n\"\n",
    "    \n",
    "    report += f\"\"\"\n",
    "║                                                                  ║\n",
    "╠══════════════════════════════════════════════════════════════════╣\n",
    "║  AI Analysis Score: {result['raw_score']:.3f}                                     ║\n",
    "║  Analysis performed by: DR Detection Model v1.0                  ║\n",
    "║                                                                  ║\n",
    "║  ⚠️  This is an AI-assisted screening tool. Final diagnosis      ║\n",
    "║     should be made by a qualified ophthalmologist.              ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "\"\"\"\n",
    "    \n",
    "    if save_path:\n",
    "        with open(save_path, 'w') as f:\n",
    "            f.write(report)\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29952c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_image_path.exists():\n",
    "    # Generate report for our sample\n",
    "    result = predict_with_tta(\n",
    "        sample_image_path, model, preprocessor, transform, THRESHOLDS, device\n",
    "    )\n",
    "    \n",
    "    report = generate_clinical_report(sample_image_path, result)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c5e4dd",
   "metadata": {},
   "source": [
    "## 7. Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7e1eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create severity scale visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 2))\n",
    "\n",
    "# Draw gradient bar\n",
    "for i in range(5):\n",
    "    ax.axvspan(i, i+1, facecolor=SEVERITY_COLORS[i], alpha=0.8)\n",
    "    ax.text(i+0.5, 0.5, f\"Grade {i}\\n{CLASS_NAMES[i].replace(' ', '\\n')}\", \n",
    "            ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Add thresholds\n",
    "for i, t in enumerate(THRESHOLDS):\n",
    "    ax.axvline(x=t, color='black', linestyle='--', linewidth=2)\n",
    "    ax.text(t, 1.1, f'{t:.2f}', ha='center', fontsize=8)\n",
    "\n",
    "ax.set_xlim(0, 5)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xticks(range(6))\n",
    "ax.set_yticks([])\n",
    "ax.set_title('ICDR Severity Scale with Optimized Thresholds', fontsize=12)\n",
    "ax.set_xlabel('Regression Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ff0b82",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. ✅ Loading trained DR detection model\n",
    "2. ✅ Single image inference with preprocessing\n",
    "3. ✅ Test Time Augmentation (TTA) for improved predictions\n",
    "4. ✅ Grad-CAM visualization for explainability\n",
    "5. ✅ Batch inference for multiple images\n",
    "6. ✅ Clinical report generation\n",
    "\n",
    "### Key Points\n",
    "- The model uses regression output with optimized thresholds\n",
    "- TTA improves prediction reliability\n",
    "- Grad-CAM shows which regions influence the prediction\n",
    "- Always verify AI predictions with clinical expertise"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
